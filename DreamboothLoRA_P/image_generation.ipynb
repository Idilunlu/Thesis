{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from accelerate import Accelerator\n",
    "from diffusers import (\n",
    "    StableDiffusionImg2ImgPipeline,\n",
    "    DiffusionPipeline,\n",
    "    DPMSolverMultistepScheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(input_args=None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--pretrained_lora\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        required=True,\n",
    "        help=\"Path to pretrained lora from huggingface.co/models.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--inference_prompt\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        required=True,\n",
    "        help=\"The prompt with identifier specifying the instance\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        required=True,\n",
    "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample_batch_size\", \n",
    "        type=int, \n",
    "        default=4, \n",
    "        help=\"Batch size for sampling images.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample_batch_count\", \n",
    "        type=int, \n",
    "        default=1, \n",
    "        help=\"Batch count for sampling images.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--inference_steps\", \n",
    "        type=int, \n",
    "        default=25, \n",
    "        help=\"Steps for inference\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--img_source\", \n",
    "        type=str, \n",
    "        default=None, \n",
    "        help=\"img_source input\"\n",
    "    )\n",
    "    if input_args is not None:\n",
    "        args = parser.parse_args(input_args)\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    accelerator = Accelerator(\n",
    "            gradient_accumulation_steps=1,\n",
    "            mixed_precision=None,\n",
    "            log_with=None,\n",
    "            logging_dir=None,\n",
    "        )\n",
    "    pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "                \"stabilityai/stable-diffusion-2-1-base\",\n",
    "                revision=None, \n",
    "                torch_dtype=torch.float32\n",
    "            )\n",
    "    pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)\n",
    "    pipeline = pipeline.to(accelerator.device)\n",
    "    print(\"Pipeline has been established. \")\n",
    "    \n",
    "    # load attention processors\n",
    "    pipeline.unet.load_attn_procs(args.pretrained_lora)\n",
    "    print(\"LoRA weight loaded.\")\n",
    "    \n",
    "    # run inference and save\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    generator = torch.Generator(device=\"cuda\").manual_seed(0)\n",
    "    #generator = torch.Generator(device=\"cpu\").manual_seed(0)\n",
    "    lora_name = args.pretrained_lora.split(\"/\")[-1]\n",
    "    prompt = args.sample_batch_size * [args.inference_prompt]\n",
    "    generated_image_dir = Path(args.output_dir) \n",
    "    #generated_image_dir.mkdir()\n",
    "    print(\"inference...\")\n",
    "\n",
    "    # 指定要遍历的文件夹路径\n",
    "    #the_folder_path = 'LUSC_Black_individual_origin/TCGA-6A-AB49-01Z-00-DX1.FDF2EED7-57A3-4019-A382-21DED11780F6'\n",
    "    the_folder_path = 'LU.ruAD_black_formalin_origin'\n",
    "    # 使用 glob 模块匹配所有以 .jpg 结尾的文件\n",
    "    jpg_files = glob.glob(os.path.join(the_folder_path, '*.jpg'))\n",
    "    # print(jpg_files)\n",
    "    for i in range(args.sample_batch_count):\n",
    "        random_number = random.randint(0, 9)\n",
    "        image_path = jpg_files[random_number]  # 使用图像文件的完整路径\n",
    "        #image_path = \"LUAD_black_formalin_origin/TCGA-95-7562-01A-01-TS1.1ba56ba5-ecd4-4eb1-ac49-3d8108114b72_13_7.jpg\"  # 验证给定的图片路径\n",
    "        image = Image.open(image_path)\n",
    "        images = pipeline(prompt, image, num_inference_steps=args.inference_steps, strength=0.6, generator=generator).images\n",
    "        #images = pipeline(prompt, num_inference_steps=args.inference_steps, generator=generator).images\n",
    "        for j, image in enumerate(images):\n",
    "            out_path = generated_image_dir / f'image_{i}_{j}.png'\n",
    "            image.save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
