{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09c824d7-cb2e-4c95-936c-d562cea11012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "def get_transforms(train=False):\n",
    "    \"\"\"\n",
    "    Takes a list of images and applies the same augmentations to all of them.\n",
    "    This is completely overengineered but it makes it easier to use in our pipeline\n",
    "    as drop-in replacement for torchvision transforms.\n",
    "    ## Example\n",
    "    ``` python\n",
    "    imgs = [Image.open(f”image{i}.png”) for i in range(1, 4)]\n",
    "    t = get_albumentations_transforms(train=True)\n",
    "    t_imgs = t(imgs) # List[torch.Tensor]\n",
    "    ```\n",
    "    For the single image case:\n",
    "    ```python\n",
    "    img = Image.open(f”image{0}.png”)\n",
    "    # or img = np.load(some_bytes)\n",
    "    t = get_albumentations_transforms(train=True)\n",
    "    t_img = t(img) # torch.Tensor\n",
    "    ```\n",
    "    \"\"\"\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    _data_transform = None\n",
    "    def _get_transform(n: int = 3):\n",
    "        data_transforms = A.Compose(\n",
    "            [\n",
    "                A.Resize(224, 224),\n",
    "                A.Normalize(mean=mean, std=std),\n",
    "                ToTensorV2(),\n",
    "            ],\n",
    "            additional_targets={f\"image{i}\": \"image\" for i in range(1, n)},\n",
    "\n",
    "        )\n",
    "        return data_transforms\n",
    "    def transform_images(images: any):\n",
    "        nonlocal _data_transform\n",
    "        if not isinstance(images, list):\n",
    "            n = 1\n",
    "            images = [images]\n",
    "        else:\n",
    "            n = len(images)\n",
    "        if _data_transform is None:\n",
    "            # instantiate once\n",
    "            _data_transform = _get_transform(n)\n",
    "        # accepts both lists of np.Array and PIL.Image\n",
    "        if isinstance(images[0], Image.Image):\n",
    "            images = [np.array(img) for img in images]\n",
    "        image_dict = {\"image\": images[0]}\n",
    "        for i in range(1, n):\n",
    "            image_dict[f\"image{i}\"] = images[i]\n",
    "        transformed = _data_transform(**image_dict)\n",
    "        transformed_images = [\n",
    "            transformed[key] for key in transformed.keys() if \"image\" in key\n",
    "        ]\n",
    "        if len(transformed_images) == 1:\n",
    "            return transformed_images[0]\n",
    "        return transformed_images\n",
    "    return transform_images\n",
    "\n",
    "\n",
    "    \n",
    "class IdilDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset to prepare the instance and class images with the prompts for fine-tuning the model.\n",
    "    It pre-processes the images and tokenizes prompts.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_path: str,\n",
    "        folder: str,\n",
    "        magnification: int,\n",
    "        transform: Optional[Callable] = None,\n",
    "        n_patches: int = 250,\n",
    "        random_selection=False,\n",
    "        limit: Optional[int] = None,\n",
    "        wsi_type: str = \"frozen\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.csv = pd.read_csv(csv_path)\n",
    "        self.csv = self.csv[self.csv[\"wsi_type\"] == wsi_type]\n",
    "\n",
    "        # Filter out unwanted tumor types\n",
    "        self.csv = self.csv[self.csv[\"Tumor Type\"] != \"Oligoastrocytoma\"]\n",
    "        \n",
    "        # Replace grade values\n",
    "        self.csv[\"Neoplasm Histologic Grade\"] = self.csv[\"Neoplasm Histologic Grade\"].replace({\"G2\": \"low grade glioma\", \"G3\": \"high grade glioma\"})\n",
    "        \n",
    "        # Replace IDH status values\n",
    "        self.csv[\"Subtype\"] = self.csv[\"Subtype\"].replace({\n",
    "            \"LGG_IDHmut-non-codel\": \"IDH mutation\",\n",
    "            \"LGG_IDHmut-codel\": \"IDH mutation\",\n",
    "            \"LGG_IDHwt\": \"wild-type IDH\"\n",
    "        })\n",
    "\n",
    "        self.folder = folder\n",
    "        self.magnification = magnification\n",
    "        self.transform = transform\n",
    "        self.n_patches = n_patches\n",
    "        self.random_selection = random_selection\n",
    "        self.slide_ids = self.csv[\"uuid\"].unique()\n",
    "        success_ids = self.load_success_ids(self.folder)\n",
    "        self.slide_ids = [x for x in self.slide_ids if x in success_ids]\n",
    "        if limit:\n",
    "            self.slide_ids = self.slide_ids[:limit]\n",
    "        self.labels = []\n",
    "        self.patches = []\n",
    "        self.load_patches()\n",
    "        self.compute_weights()\n",
    "        \n",
    "    def load_success_ids(self, feat_folder: str):\n",
    "        success_ids = set()\n",
    "        success_txt = f\"{feat_folder}/success.txt\"\n",
    "        success_db = f\"{feat_folder}/success.db\"\n",
    "        if os.path.exists(success_txt):\n",
    "            print(\"Warning: Loading success IDs from deprecated success.txt.\")\n",
    "            with open(success_txt, \"r\") as f:\n",
    "                for line in f:\n",
    "                    success_ids.add(line.strip())\n",
    "        if os.path.exists(success_db):\n",
    "            print(\"Loading success IDs from database.\")\n",
    "            conn = sqlite3.connect(success_db)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT slide_id FROM success\")\n",
    "            success_ids = set([row[0] for row in cursor.fetchall()])\n",
    "            conn.close()\n",
    "        return success_ids\n",
    "\n",
    "    def load_patches(self):\n",
    "        \"\"\"\n",
    "        Load n_patches into memory.\n",
    "        \"\"\"\n",
    "        for slide_id in tqdm(self.slide_ids, desc=\"Prefetch patches\"):\n",
    "            file = f\"{self.folder}/{slide_id}_features.h5\"\n",
    "            try:\n",
    "                with h5py.File(file, \"r\") as h5f:\n",
    "                    n_patches = min(self.n_patches, len(h5f[str(self.magnification)]))\n",
    "                    if self.random_selection:\n",
    "                        indices = random.sample(range(n_patches), n_patches)\n",
    "                    else:\n",
    "                        indices = list(range(n_patches))\n",
    "                    imgs = [\n",
    "                        Image.fromarray(h5f[str(self.magnification)][i]) for i in indices\n",
    "                    ]\n",
    "                    self.patches.append((imgs, slide_id))\n",
    "                    self.labels.append(self.get_label(slide_id))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def get_label(self, slide_id):\n",
    "        return self.csv.loc[self.csv[\"uuid\"] == slide_id, \"label\"].values[0]\n",
    "\n",
    "    def get_metadata(self, slide_id):\n",
    "        return self.csv.loc[self.csv[\"uuid\"] == slide_id]\n",
    "\n",
    "    def compute_weights(self):\n",
    "        \"\"\"\n",
    "        Compute weights for WeightedRandomSampler.\n",
    "        \"\"\"\n",
    "        class_counts = {}\n",
    "        for label in self.labels:\n",
    "            if label in class_counts:\n",
    "                class_counts[label] += 1\n",
    "            else:\n",
    "                class_counts[label] = 1\n",
    "        class_weights = {cls: 1.0 / count for cls, count in class_counts.items()}\n",
    "        self.weights = [class_weights[label] for label in self.labels]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imgs, slide_id = self.patches[idx]\n",
    "        imgs = torch.stack([self.transform(img) for img in imgs])\n",
    "        label = self.get_label(slide_id)\n",
    "        metadata = self.get_metadata(slide_id)\n",
    "        age = metadata[\"Diagnosis Age\"].values[0]\n",
    "        race = metadata[\"Race Category\"].values[0]\n",
    "        sex = metadata[\"Sex\"].values[0]\n",
    "        grade = metadata[\"Neoplasm Histologic Grade\"].values[0]\n",
    "        IDHstatus = metadata[\"Subtype\"].values[0]\n",
    "        tumortype = metadata[\"Tumor Type\"].values[0]\n",
    "        prompt = f\"a frozen brain histopathology slide of a {race.lower()}, {sex.lower()}, age {age}, has {IDHstatus.lower()}, {grade.lower()} of {tumortype.lower()}\"\n",
    "        return slide_id, imgs, label, prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7e02e25-6658-44a9-bffe-ddddd6acbc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Loading success IDs from deprecated success.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefetch patches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 536/536 [00:36<00:00, 14.66it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_path = \"/n/data2/hms/dbmi/kyu/lab/che099/data/idil_tcga_lgg_merge_idh.csv\"\n",
    "folder = \"/n/data2/hms/dbmi/kyu/lab/che099/data/tcga_lgg/frozen_patches_20x\"\n",
    "magnification = 20\n",
    "transform = get_transforms()\n",
    "n_patches = 2\n",
    "wsi_type = \"frozen\"\n",
    "ds = IdilDataSet(\n",
    "    csv_path,\n",
    "    folder=folder,\n",
    "    magnification=magnification,   \n",
    "    transform=get_transforms(),\n",
    "    n_patches=250,\n",
    "    random_selection=True,\n",
    "    limit=None,\n",
    "    wsi_type=\"frozen\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50c4632e-6f11-42b1-bfdc-49de708a996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(ds, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecd9e6c5-7f45-4e45-9d17-99fc85f19ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32cb6a62-48b3-4ac8-9e09-5fd36184f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idu675/.conda/envs/notebookenv/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ddc8206-968e-44b9-9fa8-586862342b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a7038d3-e6a1-46b7-979b-add40b05a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_id, imgs, label, prompt = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ff87497-2bd4-4afa-893b-11d725033773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cafc8ba-b925-4f4a-ae86-e0d11b2cf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(tensor, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    for t,m,s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cce716ce-46e1-4582-80d4-c7d2610d62bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47b26a0430b4184aad20ab8a0721dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=124, description='i', max=249), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(i=(0, len(imgs)-1))\n",
    "def show(i):\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(\n",
    "        denorm(imgs[i]).numpy().transpose(1,2,0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f6c42-cd92-416f-8bb7-1d9e3b450959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
